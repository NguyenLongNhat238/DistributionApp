version: "3.7"

services:
  database:
    container_name: distributions_database
    image: postgres:15.3
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=supersecret
      - POSTGRES_DB=distribution_db
    ports:
      - 5432:5432
    volumes:
      - database_data:/var/lib/postgresql/data
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  distributions:
    container_name: distributions_backend
    build:
      context: .
      dockerfile: Dockerfile
    restart: always
    command: python manage.py runserver 0.0.0.0:3300
    volumes:
      - .:/distributions
    ports:
      - "3300:3300"
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
  cache:
    container_name: distribution_cache
    image: redis:7.0-rc3-bullseye
    restart: always
    ports:
      - 6379:6379
    command: redis-server --save 20 1 --loglevel warning --requirepass JJk8iBHoFgLKtZ.zMQ!jz!T!@ozJ
    volumes:
      - cache_data:/cache_data

  celery_worker:
    container_name: distributions_celery_worker
    build: .
    volumes:
      - .:/distributions
    command: celery -A core worker --loglevel=INFO
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
  # celery_scheduler:
  #   container_name: distributions_celery_scheduler
  #   build: .
  #   volumes:
  #     - .:/distributions
  #   command: celery -A core beat -l info
  #   depends_on:
  #     - rabbitmq
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "200k"
  #       max-file: "10"
volumes:
  database_data:
    driver: local
  cache_data:
    driver: local
